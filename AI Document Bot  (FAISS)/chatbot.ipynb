{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'According to this document do you think Faiq Ahmad is a perfect fit for any company?', 'result': 'Based on the information provided in the document, Faiq Ahmad appears to have a strong background in machine learning engineering and natural language processing. They have experience in curating and preprocessing datasets, training and optimizing machine learning models, and developing NLP algorithms. They have also worked on projects involving fine-tuning models, developing a YouTube Assistant, and implementing a Transformer from scratch.\\n\\nAdditionally, Faiq Ahmad has experience in web development using MERN stack and has worked as a web developer intern.\\n\\nOverall, Faiq Ahmad seems to have a diverse skill set in both machine learning and web development, which could make them a valuable asset to a company in these areas. However, determining if someone is a perfect fit for a company would require considering other factors such as specific job requirements, team dynamics, and cultural fit, which are not mentioned in the document.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def query_pdf(query):\n",
    "    # Load document using PyPDFLoader document loader\n",
    "    loader = PyPDFLoader(\"./Faiq's Resume.pdf\")\n",
    "    documents = loader.load()\n",
    "    # Split document in chunks\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=30, separator=\"\\n\")\n",
    "    docs = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # Create vectors\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    # Persist the vectors locally on disk\n",
    "    vectorstore.save_local(\"faiss_index_constitution\")\n",
    "\n",
    "    # Load from local storage\n",
    "    persisted_vectorstore = FAISS.load_local(\"faiss_index_constitution\", embeddings)\n",
    "\n",
    "    # Use RetrievalQA chain for orchestration\n",
    "    qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(), chain_type=\"stuff\", retriever=persisted_vectorstore.as_retriever())\n",
    "    result = qa.invoke(query)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "def main():\n",
    "    query = input(\"Type in your query: \\n\")\n",
    "    while query != \"exit\":\n",
    "        query_pdf(query)\n",
    "        query = input(\"Type in your query: \\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
